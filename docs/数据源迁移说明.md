# 数据源迁移说明：从CSV到Nebula Graph查询

## 概述

所有高级分析脚本已从读取CSV文件改为直接从Nebula Graph数据库查询数据。这样可以：
- 实时获取最新数据
- 利用图数据库的查询优化
- 支持更复杂的图查询
- CSV文件仅用于批量导入，不再作为分析数据源

## 技术要点

### 1. Nebula Graph查询API

**重要**：使用 `execute().as_primitive()` 获取结果：

```python
from nebula_utils import get_nebula_session, execute_query

session = get_nebula_session()
rows = execute_query(session, "MATCH (c:Company) RETURN id(c) as company_id")
# rows 是一个包含字典的列表
for row in rows:
    company_id = row.get('company_id', '')
```

### 2. 查询结果格式

`as_primitive()` 返回的是字典列表，每个字典代表一行结果：

```python
[
    {'company_id': 'ORG_001', 'name': '公司名称', ...},
    {'company_id': 'ORG_002', 'name': '公司名称', ...},
    ...
]
```

### 3. 节点ID获取

使用 `id(node)` 获取节点的VID：

```ngql
MATCH (c:Company)
RETURN id(c) as company_id
```

### 4. 属性访问

使用 `Tag.Property` 格式访问属性：

```ngql
MATCH (c:Company)
RETURN c.Company.name as name,
       c.Company.legal_person as legal_person
```

## 修改的文件

### 1. `src/analysis/nebula_utils.py` (新建)

提供统一的Nebula Graph连接和查询接口：

```python
def get_nebula_session() -> Session:
    """获取Nebula Graph session"""
    # 创建连接池并返回session

def execute_query(session: Session, query: str):
    """执行查询并返回结果列表"""
    result = session.execute(query)
    if not result.is_succeeded():
        raise RuntimeError(...)
    return result.as_primitive()  # 关键：使用as_primitive()
```

### 2. `src/analysis/fraud_rank.py`

**主要修改**：
- `load_weighted_graph()`: 从CSV读取 → Nebula Graph查询
- `initialize_risk_seeds()`: 从CSV读取 → Nebula Graph查询
- `analyze_fraud_rank_results()`: 从CSV读取 → Nebula Graph查询

**查询示例**：
```python
# 查询所有边关系
controls_query = """
MATCH (c1:Company)-[:CONTROLS]->(c2:Company)
RETURN id(c1) as from_node, id(c2) as to_node
"""
rows = execute_query(session, controls_query)
```

### 3. `src/analysis/circular_trade.py`

**主要修改**：
- `get_related_companies()`: 从CSV读取 → Nebula Graph查询
- `detect_fan_out_fan_in()`: 从CSV读取 → Nebula Graph查询

**查询示例**：
```python
# 查询资金流
money_flow_query = """
MATCH (payer:Company)-[:PAYS]->(t:Transaction)-[:RECEIVES]->(receiver:Company)
RETURN id(payer) as payer_company,
       id(receiver) as receiver_company,
       t.Transaction.amount as transaction_amount,
       t.Transaction.transaction_date as transaction_date
"""
```

### 4. `src/analysis/shell_company.py`

**主要修改**：
- `count_companies_with_same_legal_person()`: 从CSV读取 → Nebula Graph查询
- `extract_shell_company_features()`: 从CSV读取 → Nebula Graph查询
- `identify_shell_networks()`: 从CSV读取 → Nebula Graph查询

**查询示例**：
```python
# 查询公司的支付交易
pays_query = f"""
MATCH (c:Company)-[:PAYS]->(t:Transaction)
WHERE id(c) == "{company_id}"
RETURN id(t) as txn_id, t.Transaction.amount as amount
"""
```

### 5. `src/analysis/collusion.py`

**主要修改**：
- `analyze_collusion_patterns()`: 从CSV读取 → Nebula Graph查询
- `detect_collusion_network()`: 从CSV读取 → Nebula Graph查询

**查询示例**：
```python
# 查询共享法人的公司组
legal_person_query = """
MATCH (p:Person)-[:LEGAL_PERSON]->(c:Company)
WITH p, collect(id(c)) as companies
WHERE size(companies) >= 2
RETURN companies
"""
```

## 常见查询模式

### 1. 查询节点

```python
query = """
MATCH (c:Company)
RETURN id(c) as company_id, c.Company.name as name
"""
```

### 2. 查询边关系

```python
query = """
MATCH (c1:Company)-[:CONTROLS]->(c2:Company)
RETURN id(c1) as from_node, id(c2) as to_node
"""
```

### 3. 多跳查询

```python
query = """
MATCH (c1:Company)-[:CONTROLS*0..2]-(c2:Company)
WHERE id(c1) == "ORG_001"
RETURN DISTINCT id(c2) as company_id
"""
```

### 4. 路径查询

```python
query = """
MATCH (payer:Company)-[:PAYS]->(t:Transaction)-[:RECEIVES]->(receiver:Company)
RETURN id(payer) as payer, id(receiver) as receiver
"""
```

### 5. 聚合查询

```python
query = """
MATCH (c:Company)-[:PARTY_B]->(con:Contract)
WHERE id(c) IN ["ORG_001", "ORG_002"]
RETURN count(con) as contract_count
"""
```

## 注意事项

### 1. Session管理

**必须**在finally块中释放session：

```python
session = None
try:
    session = get_nebula_session()
    # 执行查询...
finally:
    if session:
        session.release()
```

### 2. 字符串转义

在WHERE子句中使用节点ID时，需要用引号：

```python
# 正确
WHERE id(c) == "{company_id}"

# 错误
WHERE id(c) == {company_id}  # 缺少引号
```

### 3. IN子句格式

使用IN子句时，需要手动构建字符串列表：

```python
company_ids_str = ', '.join([f'"{c}"' for c in company_cluster])
query = f"""
WHERE id(c) IN [{company_ids_str}]
"""
```

### 4. ORDER BY

ORDER BY必须使用RETURN中的列名，不能使用属性路径：

```python
# 正确
RETURN con.Contract.sign_date as sign_date
ORDER BY sign_date

# 错误
ORDER BY con.Contract.sign_date
```

### 5. 空值处理

查询结果可能包含None值，需要处理：

```python
amount = float(row.get('amount', 0) or 0)
name = row.get('name', '') or 'Unknown'
```

## 性能优化建议

### 1. 批量查询

对于需要多次查询的场景，考虑使用批量查询：

```python
# 一次性查询所有公司的交易
query = """
MATCH (c:Company)-[:PAYS]->(t:Transaction)
RETURN id(c) as company_id, collect(t) as transactions
"""
```

### 2. 使用索引

确保在常用查询字段上创建索引：

```ngql
CREATE TAG INDEX company_name_index ON Company(name);
```

### 3. 限制结果数量

对于大数据集，使用LIMIT：

```python
query = """
MATCH (c:Company)
RETURN id(c) as company_id
LIMIT 1000
"""
```

## 测试验证

所有脚本已通过测试：

```bash
# 测试所有脚本
uv run python src/analysis/fraud_rank.py      # ✅ 成功
uv run python src/analysis/circular_trade.py # ✅ 成功
uv run python src/analysis/shell_company.py   # ✅ 成功
uv run python src/analysis/collusion.py       # ✅ 成功

# 运行完整套件
uv run python src/analysis/run_all_analysis.py # ✅ 成功
```

## 迁移前后对比

| 方面 | CSV读取 | Nebula Graph查询 |
|------|---------|------------------|
| **数据实时性** | 需要重新生成CSV | 实时查询最新数据 |
| **性能** | 需要加载整个文件 | 只查询需要的数据 |
| **灵活性** | 受限于CSV结构 | 支持复杂图查询 |
| **维护** | 需要同步CSV和数据库 | 单一数据源 |
| **扩展性** | 难以支持复杂关系 | 支持多跳查询 |

## 总结

✅ 所有四个分析脚本已成功迁移到Nebula Graph查询
✅ 使用统一的 `nebula_utils` 模块管理连接和查询
✅ 所有脚本已通过测试验证
✅ CSV文件现在仅用于批量导入，不再作为分析数据源

现在所有分析都直接从Nebula Graph实时查询数据，确保分析结果的准确性和实时性！

